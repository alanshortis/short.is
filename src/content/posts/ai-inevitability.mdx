---
title: 'AI inevitability'
description: 'Must AI be embraced, is it a dumb fad we can ignore, or is it more complicated than that?'
pubDate: '2025-04-25'
showAgeWarning: true
---

As usual there are vocal minorities on two extremes of a technology argument. Some will tell you that AI is going to change the world. Others will point to NFTs, 3D TVs and the metaverse as claimed game changers that burst quickly and spectacularly.

The reality is somewhere in the middle.

## What will go away

The days of LinkedIn being unusable because of endless AI generated slop (those action figures are especially egregious) will pass. Some people see these possibilities and confidently claim that it's over for artists, designers, and coders. Why do we need a human when a computer can do what I want?

We'll see that what we build will converge into one derivative design language. We'll get sick of AI assistants that fail the moment an enquiry strays beyond a known issue. We'll crave the human touch, even if this is initially sold to us as being somehow premium.

## What will stay

Working remotely, I spend a good amount of time in Google Meet calls. No one wants to be one to take notes for those who can't attend. Integration with Gemini means we now get good quality summaries of what was said and by whom. Generating a summary of a lengthy email or document helps me decide if I should read it now or if it's less pressing than what's already on my plate.

I rarely use Google for anything beyond a straight forward search anymore. Where it used to be normal to sift through a few pages of results when trying to solve an issue with some code, I ask Perplexity a well worded and nuanced question that includes what I already know and it'll give me a good answer, with sources. Whatever the answer lacks, I can ask for clarification and it'll keep the context of our conversation while providing a new answer.

Code editors have had autocomplete for a long time. With some AI assistance, editors can turbocharge this with an understanding of the codebase, some context of what is being written, and established norms. When I hit <kbd>tab</kbd> to accept a suggestion, it usually needs an edit. But it's more correct now than it was even 2 months ago.

## Ethics

Plagiarism is not going to stop. Models run at a huge financial loss. It is simply not possible to compensate human creators and they will continue to steamroll through anything and everything published online, ignoring any directives to the contrary.

Google makes all of its money from advertising, and when a search term just provides a list of results it's very easy to identify sponsored items that may or may not be relevant. If OpenAI choose to follow this path, are they going to weave sponsored information into results? If someone decides to ask about the possible side effects of a drug, will the answer be weighted towards the pharmaceutical company that paid for the placement?

Models are only as impartial as the data they are trained on. A child raised by parents with, shall we say, _outdated ideals_ will very likely grow up to echo those ideals.

Even if all of this could somehow be solved, the [energy consumption is vast](https://www.vox.com/climate/2024/3/28/24111721/climate-ai-tech-energy-demand-rising) and people care much more about convenience than the environment. What's the real cost of all the worthless, artless, slop pumped out 24/7?

## So?

I have no idea how to balance the benefits against the ethical issues. I don't think AI is going to be essential for everybody but there is unfortunately truth to the argument that while AI isn't taking jobs it will make employers favour people who can use it effectively. If you work in a corporate environment that is driven by delivery and impact, the expectations put on individual contributors are going to factor in the use of AI. Part of my job includes interviewing new candidates, and we have yet to introduce any measures related to AI. It's only a matter of time before we do.

[This _excellent_ 99% invisible episode](https://99percentinvisible.org/episode/children-of-the-magenta-automation-paradox-pt-1/) discusses the dulling of skills where automation is the norm. When automation doesn't make sense, operators need to be able to fall back to actual skill and take control. Land the plane themselves. This is where the danger lies, assuming we haven't already cooked the earth to an extinction level temperature.
