---
title: 'AI inevitability'
description: 'How can the usefulness of AI be weighed against the many ethical issues it presents?'
pubDate: '2025-04-25'
showAgeWarning: true
---

Some will tell you that AI is going to change the world. Others will point to NFTs, 3D TVs and the metaverse as false utopias that burst quickly and were forgotten just as fast. The reality is probably somewhere in the middle.

How can the usefulness of AI be weighed against the many ethical issues it presents?

## Fads

The days of LinkedIn being slammed with endless AI generated slop (those action figures are especially egregious) will pass. Some people see these possibilities and confidently claim that it's over for artists, designers, coders, and human customer support. Why do we need a human when a computer can do it?

AI art and design with no human oversight will converge into one derivative design language. We'll get sick of AI assistants that fail the moment an enquiry strays beyond a known issue. We'll crave the human touch, even if this is initially sold to us as being somehow premium.

AI being pumped into everything will contract eventually, especially as the novelty wears off and people can see that, so often, it's just total shit. Google have gone from the standard-bearers of search to shipping AI results that will [explain the meaning of phrases that are entirely fabricated on the spot](https://arstechnica.com/ai/2025/04/google-searchs-made-up-ai-explanations-for-sayings-no-one-ever-said-explained/). You might argue that this is something that is being developed and improved out in the open, but it's still turbo-misinformation.

## What's already good

I like to think of LLMs as calculators for language. While it's still fine and possible to do long winded and complex mathematics manually we have all accepted that calculators and analysis tools are just better for this kind of thing.

An LLM can analyse a huge number of documents, summarise, find patterns, make connections, and come to conclusions that it would take a human years to arrive at.

These tools work best when you collaborate with them. If you treat a series of prompts and responses like a conversation with a human you get better, more nuanced results. Tell it when you already know, what you want to achieve, and it'll help you get there. Writing code with AI doesn't have to be a vibe-coding nightmare, it can actually pair with your fairly effectively.

Forget AI as a creative force, and use it to work with what **you** are creating.

## Ethics

This is where I struggle.

Plagiarism is not going to stop. Models run at a huge financial loss. It is simply not possible to compensate human creators, so bots will continue to steamroll through anything and everything published online ignoring any directives to the contrary.

Google makes all of its money from advertising, and when a search term just provides a list of results it's very easy to identify sponsored items that may or may not be relevant. If OpenAI were to choose to follow this path, are they going to weave sponsored information into results? If someone decides to ask about the possible side effects of a drug, will the answer be weighted towards a pharmaceutical company that paid for the placement even if the model itself knows it's not the best option?

Models are only as impartial as the data they are trained on. A child raised by parents with bigoted and outdated ideals will very likely grow up to echo those ideals. Even after training, owners of models can weight the probabilities of certain outcomes to meet their agenda. We have definitely seen Musk do this with XAI in efforts to push certain narratives in <del>his nazi bar</del> <ins>X</ins>.

A doomsday scenario for humans at the hands of AI isn't a thought experiment. Facial recognition to match security camera footage to mugshots or driving licence photos has been trusted by law enforcement and led to arrests of innocent people. The biases in the data used to train the models are so obvious and predictable, I'll bet you already know what [this article](https://amnesty.ca/features/racial-bias-in-facial-recognition-algorithms/) says before you read it.

Even if all of this could somehow be solved, the [energy and water consumption is vast](https://www.vox.com/climate/2024/3/28/24111721/climate-ai-tech-energy-demand-rising) and people care much more about convenience than the environment. What's the real cost of making a picture of your dog in a stolen Studio Ghibli style?

## A balance

I have no idea how to balance the benefits against the ethical issues. There is unfortunately truth to the argument that while AI isn't likely to eliminate jobs, it will make employers favour people who can use it effectively. It's another tool to be understood and harnessed to keep being a productive proletarian. If you work in a corporate environment that is driven by delivery and impact, the expectations put on individual contributors are going to factor in the use of AI.

If I want to slow down and just enjoy writing, that's what I do. AI has a minuscule presence in my non-work life and is almost exclusively using Perplexity in place of Google. I have found it provides a much boarder, more contextual, and well cited response than 65 open tabs from a keyword search.

## No, it's probably a disaster

[This _excellent_ 99% invisible episode](https://99percentinvisible.org/episode/children-of-the-magenta-automation-paradox-pt-1/) discusses the dulling of skills where automation is the norm. When automation doesn't make sense, operators need to be able to fall back to actual skill and take control. Land the plane themselves. This is where the danger lies, assuming we haven't already cooked the earth to an extinction level temperature. How long until knowing things seems kind of quaint?

Irregardless of how disciplined some of us will choose to be - keeping AI use confined to a required part of being a productive part of a corporate machine - AI is going to be inside everything we do. Online, any kind of surveillance in public spaces, your own internet-of-things devices. It's frighteningly unregulated and the people at the helm of the major AI players have already shown that that they'll bend a knee to a government that is more authoritarian by the day.
